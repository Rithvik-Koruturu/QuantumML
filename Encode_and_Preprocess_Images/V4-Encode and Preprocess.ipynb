{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37574f12-ffb2-43d7-95b0-7e21832853bb",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c532b480-55f7-4977-91e2-e5155b9bff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cat images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:36<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Dog images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:47<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1992/1992 [00:10<00:00, 189.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Quantum encoding complete with dynamic qubits and padded Amplitude Embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from math import ceil, log2\n",
    "\n",
    "# === Setup ===\n",
    "dataset_path = \"D:/datasets/PetImages\"\n",
    "categories = [\"Cat\", \"Dog\"]\n",
    "num_images_per_category = 1000\n",
    "\n",
    "# === Feature Extraction using SIFT ===\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros(128)\n",
    "    return descriptors.mean(axis=0)\n",
    "\n",
    "# === Load Dataset in Parallel ===\n",
    "def process_image(category, image_file):\n",
    "    image_path = os.path.join(dataset_path, category, image_file)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        feat = extract_features(image)\n",
    "        return feat, category\n",
    "    return None, None\n",
    "\n",
    "all_features, labels = [], []\n",
    "for category in categories:\n",
    "    print(f\"Processing {category} images...\")\n",
    "    path = os.path.join(dataset_path, category)\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith(\".jpg\")][:num_images_per_category]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda f: process_image(category, f), image_files), total=len(image_files)))\n",
    "    \n",
    "    for feat, label in results:\n",
    "        if feat is not None:\n",
    "            all_features.append(feat)\n",
    "            labels.append(label)\n",
    "\n",
    "# === Standardization + PCA ===\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(all_features)\n",
    "\n",
    "pca = PCA(0.95)  # retain 95% variance\n",
    "reduced = pca.fit_transform(scaled)\n",
    "\n",
    "# === Quantum Configuration ===\n",
    "original_dim = reduced.shape[1]\n",
    "n_qubits = int(ceil(log2(original_dim)))\n",
    "dim = 2**n_qubits\n",
    "\n",
    "# Pad to match 2^n\n",
    "def pad(vec, target_dim):\n",
    "    if len(vec) < target_dim:\n",
    "        return np.pad(vec, (0, target_dim - len(vec)))\n",
    "    else:\n",
    "        return vec[:target_dim]\n",
    "\n",
    "# Quantum Device\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "# QAOA Layer\n",
    "def qaoa_layer(gamma, beta, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.CZ(wires=[wires[i], wires[(i+1)%len(wires)]])\n",
    "    for i in range(len(wires)):\n",
    "        qml.RX(gamma, wires=i)\n",
    "        qml.RZ(beta, wires=i)\n",
    "\n",
    "# QNode\n",
    "@qml.qnode(dev)\n",
    "def quantum_model(x, gamma=0.5, beta=0.5):\n",
    "    qml.AmplitudeEmbedding(x / np.linalg.norm(x), wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qaoa_layer(gamma, beta, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# === Encode All with Quantum Circuit ===\n",
    "quantum_outputs = []\n",
    "print(\"Quantum encoding in progress...\")\n",
    "for vec in tqdm(reduced):\n",
    "    vec_padded = pad(vec, dim)\n",
    "    vec_pnp = pnp.array(vec_padded, requires_grad=False)\n",
    "    result = quantum_model(vec_pnp)\n",
    "    quantum_outputs.append(result)\n",
    "\n",
    "# === Save Output ===\n",
    "final_data = {\n",
    "    \"quantum_encoded\": quantum_outputs,\n",
    "    \"labels\": labels\n",
    "}\n",
    "with open(\"quantum_real_time_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_data, f)\n",
    "\n",
    "print(\" Quantum encoding complete with dynamic qubits and padded Amplitude Embedding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa5d5388-cdef-4a7c-a8d0-895e412b22aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Quantum Encoded Outputs (First 5):\n",
      "Sample 1:\n",
      "  Label  : Cat\n",
      "  Encoding: [array(0.72441723), array(0.3273361), array(0.42893438), array(-0.40457318), array(0.57103061)]\n",
      "\n",
      "Sample 2:\n",
      "  Label  : Cat\n",
      "  Encoding: [array(0.84443226), array(0.78705741), array(0.6994629), array(0.43953125), array(0.71539102)]\n",
      "\n",
      "Sample 3:\n",
      "  Label  : Cat\n",
      "  Encoding: [array(0.72123709), array(0.81350795), array(-0.55592995), array(0.57628599), array(0.50335103)]\n",
      "\n",
      "Sample 4:\n",
      "  Label  : Cat\n",
      "  Encoding: [array(0.83038269), array(0.69308658), array(0.20428599), array(0.45211841), array(0.01848554)]\n",
      "\n",
      "Sample 5:\n",
      "  Label  : Cat\n",
      "  Encoding: [array(0.78047408), array(0.65008033), array(0.6198495), array(0.48470764), array(0.36771226)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the quantum encoded data\n",
    "with open(\"quantum_real_time_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Print the first 5 quantum encoded vectors and their labels\n",
    "print(\" Quantum Encoded Outputs (First 5):\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"  Label  :\", data[\"labels\"][i])\n",
    "    print(\"  Encoding:\", data[\"quantum_encoded\"][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753757f0-ee67-48c4-ab23-1b1fcd4c6fa0",
   "metadata": {},
   "source": [
    "# Full Frame Image size and Alterable Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b4febb-7cb1-4e07-81f5-449ab3bff02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fef27d2a-1b80-4675-a066-91ab47ea98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:/datasets/PetImages\"\n",
    "categories = [\"Cat\", \"Dog\"]\n",
    "num_images_per_category = 1000\n",
    "all_features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "025cd9c3-b4a0-4ade-82c2-fca295b52660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros((128,))\n",
    "    return descriptors.mean(axis=0)  # returns a 128-dim vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c29a42-1623-4b98-a93b-61f03a26eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Cat images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:04<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Dog images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:08<00:00, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(dataset_path, category)\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith(\".jpg\")][:num_images_per_category]\n",
    "    print(f\"Encoding {category} images...\")\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        try:\n",
    "            image_path = os.path.join(path, image_file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                continue\n",
    "            features = extract_features(image)\n",
    "            all_features.append(features)\n",
    "            labels.append(category)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0dd077b-9d69-4ff6-ac47-bab3540cacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(all_features)\n",
    "\n",
    "# Dynamic number of PCA components (limit to 8)\n",
    "n_components = min(8, scaled_features.shape[1])\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_features = pca.fit_transform(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e56c3f1-2847-49e3-9fb8-14646de27865",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = n_components\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "def qaoa_layer(gamma, beta, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.CZ(wires=[wires[i], wires[(i + 1) % len(wires)]])\n",
    "    for i in range(len(wires)):\n",
    "        qml.RX(2 * gamma, wires=i)\n",
    "        qml.RZ(2 * beta, wires=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54552804-019d-4dbb-89a1-0615a5fd1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def quantum_model(x, gamma=0.5, beta=0.5):\n",
    "    padded = np.zeros(2**n_qubits)\n",
    "    norm = np.linalg.norm(x)\n",
    "    padded[:len(x)] = x / norm if norm != 0 else x\n",
    "    qml.AmplitudeEmbedding(features=padded, wires=range(n_qubits), normalize=True)\n",
    "    qaoa_layer(gamma, beta, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d3796de-9baa-4687-aa95-947760717825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1992/1992 [00:18<00:00, 109.32it/s]\n"
     ]
    }
   ],
   "source": [
    "quantum_outputs = []\n",
    "\n",
    "print(\"Quantum encoding in progress...\")\n",
    "for vec in tqdm(reduced_features):\n",
    "    vec = pnp.array(vec, requires_grad=False)\n",
    "    result = quantum_model(vec)\n",
    "    quantum_outputs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e72b7bdb-544c-4e53-b36c-98350afa579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline complete with adaptive qubit encoding and no resizing.\n"
     ]
    }
   ],
   "source": [
    "final_data = {\n",
    "    \"quantum_encoded\": quantum_outputs,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(\"quantum_real_time_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_data, f)\n",
    "\n",
    "print(\" Pipeline complete with adaptive qubit encoding and no resizing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c38f8f27-5625-44a7-9ea9-40d5011018cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Preview of Encoded Quantum Features:\n",
      "Label: Cat, Quantum Output: 0.5403023058681407\n",
      "Label: Cat, Quantum Output: 0.5403023058681409\n",
      "Label: Cat, Quantum Output: 0.5403023058681404\n",
      "Label: Cat, Quantum Output: 0.5403023058681408\n",
      "Label: Cat, Quantum Output: 0.5403023058681403\n"
     ]
    }
   ],
   "source": [
    "# ðŸ–¨ï¸ Print Head\n",
    "print(\"\\n Preview of Encoded Quantum Features:\")\n",
    "for i in range(5):\n",
    "    print(f\"Label: {labels[i]}, Quantum Output: {quantum_outputs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1a178-2426-41a6-85c6-cc939df5a3fa",
   "metadata": {},
   "source": [
    "# ORB VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a0ccc21-fe18-4340-822d-b1b5e54ae7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9dbbc12-7648-4012-8ea8-cfc219ca6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:/datasets/PetImages\"\n",
    "categories = [\"Cat\", \"Dog\"]\n",
    "num_images_per_category = 1000\n",
    "all_features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "193d7f01-4e4a-4a94-8d8b-48c6e54d4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ Feature extraction using ORB (Star Feature Alternative)\n",
    "def extract_features(image):\n",
    "    orb = cv2.ORB_create(nfeatures=128)\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros((128,))\n",
    "    return descriptors.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d688171-bc6f-49be-986f-0deb37812dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Cat images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:07<00:00, 126.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Dog images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:09<00:00, 102.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(dataset_path, category)\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith(\".jpg\")][:num_images_per_category]\n",
    "    print(f\"Encoding {category} images...\")\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        try:\n",
    "            image_path = os.path.join(path, image_file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                continue\n",
    "            features = extract_features(image)\n",
    "            all_features.append(features)\n",
    "            labels.append(category)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6d804bf-4ec9-4738-b512-e8bee435601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 128  # or any fixed dimension you choose\n",
    "\n",
    "def pad_or_truncate(feature, length=fixed_length):\n",
    "    if feature is None:\n",
    "        return np.zeros(length)\n",
    "    if len(feature) >= length:\n",
    "        return feature[:length]\n",
    "    else:\n",
    "        return np.pad(feature, (0, length - len(feature)), mode='constant')\n",
    "\n",
    "# Apply fix to all features\n",
    "fixed_features = np.array([pad_or_truncate(f) for f in all_features])\n",
    "\n",
    "# Now scale and reduce\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(fixed_features)\n",
    "\n",
    "n_components = min(8, scaled_features.shape[1])\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_features = pca.fit_transform(scaled_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c501309-fc60-4f16-a77a-fb580c33bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = n_components\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "def qaoa_layer(gamma, beta, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.CZ(wires=[wires[i], wires[(i + 1) % len(wires)]])\n",
    "    for i in range(len(wires)):\n",
    "        qml.RX(2 * gamma, wires=i)\n",
    "        qml.RZ(2 * beta, wires=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac9dd2dd-5266-42ab-9449-ccd3fdd8201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def quantum_model(x, gamma=0.5, beta=0.5):\n",
    "    padded = np.zeros(2**n_qubits)\n",
    "    norm = np.linalg.norm(x)\n",
    "    padded[:len(x)] = x / norm if norm != 0 else x\n",
    "    qml.AmplitudeEmbedding(features=padded, wires=range(n_qubits), normalize=True)\n",
    "    qaoa_layer(gamma, beta, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da6dbdba-f526-41b0-ad15-70b495d34daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1992/1992 [00:22<00:00, 89.37it/s]\n"
     ]
    }
   ],
   "source": [
    "quantum_outputs = []\n",
    "\n",
    "print(\"Quantum encoding in progress...\")\n",
    "for vec in tqdm(reduced_features):\n",
    "    vec = pnp.array(vec, requires_grad=False)\n",
    "    result = quantum_model(vec)\n",
    "    quantum_outputs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88d016f1-f598-4ad1-8321-97d3a8b6dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline complete with adaptive qubit encoding and no resizing.\n"
     ]
    }
   ],
   "source": [
    "final_data = {\n",
    "    \"quantum_encoded\": quantum_outputs,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(\"quantum_real_time_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_data, f)\n",
    "\n",
    "print(\" Pipeline complete with adaptive qubit encoding and no resizing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5319688-02f9-4f72-b176-ad9b4e0456b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Preview of Encoded Quantum Features:\n",
      "Label: Cat, Quantum Output: 0.5403023058681404\n",
      "Label: Cat, Quantum Output: 0.5403023058681404\n",
      "Label: Cat, Quantum Output: 0.5403023058681407\n",
      "Label: Cat, Quantum Output: 0.5403023058681405\n",
      "Label: Cat, Quantum Output: 0.5403023058681402\n"
     ]
    }
   ],
   "source": [
    "# ðŸ–¨ï¸ Print Head\n",
    "print(\"\\n Preview of Encoded Quantum Features:\")\n",
    "for i in range(5):\n",
    "    print(f\"Label: {labels[i]}, Quantum Output: {quantum_outputs[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "pennylane"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
