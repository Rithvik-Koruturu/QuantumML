{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80375c25-b512-4a19-a2f0-fd1a5e314292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Aster images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:33<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Daisy images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:20<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Iris images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 53.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Lavender images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:32<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Lily images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:24<00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Marigold images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:29<00:00, 33.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Orchid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:21<00:00, 46.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Poppy images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Rose images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:24<00:00, 40.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Sunflower images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:25<00:00, 38.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 374.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding complete for multi-class flower dataset with padded Amplitude Embedding and QAOA layer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from math import ceil, log2\n",
    "\n",
    "# === Setup ===\n",
    "dataset_path = r\"D:\\Images_anantwave\\Mulit_class\\Flower Classification\\Training Data\"\n",
    "categories = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n",
    "num_images_per_category = 1000\n",
    "\n",
    "# === SIFT Feature Extraction ===\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros(128)\n",
    "    return descriptors.mean(axis=0)\n",
    "\n",
    "# === Parallel Image Processing ===\n",
    "def process_image(category, image_file):\n",
    "    image_path = os.path.join(dataset_path, category, image_file)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        try:\n",
    "            image = cv2.resize(image, (256, 256))  # Resize to fixed size\n",
    "            feat = extract_features(image)\n",
    "            return feat, category\n",
    "        except Exception as e:\n",
    "            print(f\"Failed processing {image_file}: {e}\")\n",
    "    return None, None\n",
    "\n",
    "# === Feature Extraction Loop ===\n",
    "all_features, labels = [], []\n",
    "for category in categories:\n",
    "    print(f\"Processing {category} images...\")\n",
    "    path = os.path.join(dataset_path, category)\n",
    "    valid_exts = [\".jpg\", \".jpeg\", \".png\"]\n",
    "    image_files = [f for f in os.listdir(path) if os.path.splitext(f)[1].lower() in valid_exts][:num_images_per_category]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda f: process_image(category, f), image_files), total=len(image_files)))\n",
    "\n",
    "    for feat, label in results:\n",
    "        if feat is not None:\n",
    "            all_features.append(feat)\n",
    "            labels.append(label)\n",
    "\n",
    "# === Standardization and PCA ===\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(all_features)\n",
    "\n",
    "pca = PCA(0.95)  # retain 95% variance\n",
    "reduced = pca.fit_transform(scaled)\n",
    "\n",
    "# === Quantum Configuration ===\n",
    "original_dim = reduced.shape[1]\n",
    "n_qubits = int(ceil(log2(original_dim)))\n",
    "dim = 2**n_qubits\n",
    "\n",
    "def pad(vec, target_dim):\n",
    "    return np.pad(vec, (0, target_dim - len(vec))) if len(vec) < target_dim else vec[:target_dim]\n",
    "\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "def qaoa_layer(gamma, beta, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.CZ(wires=[wires[i], wires[(i+1)%len(wires)]])\n",
    "    for i in range(len(wires)):\n",
    "        qml.RX(gamma, wires=i)\n",
    "        qml.RZ(beta, wires=i)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_model(x, gamma=0.5, beta=0.5):\n",
    "    qml.AmplitudeEmbedding(x / np.linalg.norm(x), wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qaoa_layer(gamma, beta, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# === Quantum Encoding ===\n",
    "quantum_outputs = []\n",
    "print(\"Quantum encoding in progress...\")\n",
    "for vec in tqdm(reduced):\n",
    "    vec_padded = pad(vec, dim)\n",
    "    vec_pnp = pnp.array(vec_padded, requires_grad=False)\n",
    "    result = quantum_model(vec_pnp)\n",
    "    quantum_outputs.append(result)\n",
    "\n",
    "# === Save Output ===\n",
    "final_data = {\n",
    "    \"quantum_encoded\": quantum_outputs,\n",
    "    \"labels\": labels\n",
    "}\n",
    "with open(\"quantum_flower_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_data, f)\n",
    "\n",
    "print(\"Quantum encoding complete for multi-class flower dataset with padded Amplitude Embedding and QAOA layer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0d8b23-29f1-4180-b039-e68e98cc56b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Preview of Encoded Quantum Features:\n",
      "Label: Aster, Quantum Output: [array(0.81240592), array(0.70811413), array(-0.05888468), array(0.21134427), array(0.37668806)]\n",
      "Label: Aster, Quantum Output: [array(0.81069066), array(0.81401901), array(0.33420244), array(0.75918078), array(0.75333112)]\n",
      "Label: Aster, Quantum Output: [array(0.8318538), array(0.76937374), array(0.6756186), array(0.54293519), array(0.4049052)]\n",
      "Label: Aster, Quantum Output: [array(0.77895201), array(0.74673869), array(0.58030405), array(0.58846052), array(-0.35672302)]\n",
      "Label: Aster, Quantum Output: [array(0.80686465), array(0.74998474), array(0.19227684), array(0.56563448), array(0.00135146)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Preview of Encoded Quantum Features:\")\n",
    "for i in range(5):\n",
    "    print(f\"Label: {labels[i]}, Quantum Output: {quantum_outputs[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anantwave)",
   "language": "python",
   "name": "anantwave"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
