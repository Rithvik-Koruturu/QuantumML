{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e6012c-83ac-4768-bd74-afd32e65263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\encode\\anantwave\\Scripts\\python.exe\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\encode\\anantwave\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa02f2f-8e97-4977-af34-c8c80dd112e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cat images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:16<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dog images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:55<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wild images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:50<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:14<00:00, 208.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum encoding complete for Cat, Dog, and Wildlife classes with padded Amplitude Embedding and QAOA layer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from math import ceil, log2\n",
    "\n",
    "# === Setup ===\n",
    "dataset_path = \"C:/Users/HP/encode/anantwave/Multi_class/train\"\n",
    "categories = [\"cat\", \"dog\", \"wild\"]\n",
    "num_images_per_category = 1000  # You can adjust this if needed\n",
    "\n",
    "# === Feature Extraction using SIFT ===\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros(128)\n",
    "    return descriptors.mean(axis=0)\n",
    "\n",
    "# === Load Dataset in Parallel ===\n",
    "def process_image(category, image_file):\n",
    "    image_path = os.path.join(dataset_path, category, image_file)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        feat = extract_features(image)\n",
    "        return feat, category\n",
    "    return None, None\n",
    "\n",
    "all_features, labels = [], []\n",
    "for category in categories:\n",
    "    print(f\"Processing {category} images...\")\n",
    "    path = os.path.join(dataset_path, category)\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith(\".jpg\")][:num_images_per_category]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda f: process_image(category, f), image_files), total=len(image_files)))\n",
    "\n",
    "    for feat, label in results:\n",
    "        if feat is not None:\n",
    "            all_features.append(feat)\n",
    "            labels.append(label)\n",
    "\n",
    "# === Standardization + PCA ===\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(all_features)\n",
    "\n",
    "pca = PCA(0.95)\n",
    "reduced = pca.fit_transform(scaled)\n",
    "\n",
    "# === Quantum Configuration ===\n",
    "original_dim = reduced.shape[1]\n",
    "n_qubits = int(ceil(log2(original_dim)))\n",
    "dim = 2**n_qubits\n",
    "\n",
    "def pad(vec, target_dim):\n",
    "    if len(vec) < target_dim:\n",
    "        return np.pad(vec, (0, target_dim - len(vec)))\n",
    "    else:\n",
    "        return vec[:target_dim]\n",
    "\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "def qaoa_layer(gamma, beta, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.CZ(wires=[wires[i], wires[(i+1)%len(wires)]])\n",
    "    for i in range(len(wires)):\n",
    "        qml.RX(gamma, wires=i)\n",
    "        qml.RZ(beta, wires=i)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_model(x, gamma=0.5, beta=0.5):\n",
    "    qml.AmplitudeEmbedding(x / np.linalg.norm(x), wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qaoa_layer(gamma, beta, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# === Encode All with Quantum Circuit ===\n",
    "quantum_outputs = []\n",
    "print(\"Quantum encoding in progress...\")\n",
    "for vec in tqdm(reduced):\n",
    "    vec_padded = pad(vec, dim)\n",
    "    vec_pnp = pnp.array(vec_padded, requires_grad=False)\n",
    "    result = quantum_model(vec_pnp)\n",
    "    quantum_outputs.append(result)\n",
    "\n",
    "# === Save Output ===\n",
    "final_data = {\n",
    "    \"quantum_encoded\": quantum_outputs,\n",
    "    \"labels\": labels\n",
    "}\n",
    "with open(\"quantum_AFHQ_encoded.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_data, f)\n",
    "\n",
    "print(\"Quantum encoding complete for Cat, Dog, and Wildlife classes with padded Amplitude Embedding and QAOA layer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36c245f-69a6-4f9c-b9fc-96a62a52dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum Encoded Outputs (First 5):\n",
      "Sample 1:\n",
      "  Label    : cat\n",
      "  Encoding : [array(0.8701905), array(0.73895513), array(0.77356545), array(0.62696102), array(-0.26144835)]\n",
      "\n",
      "Sample 2:\n",
      "  Label    : cat\n",
      "  Encoding : [array(0.83470984), array(0.75914326), array(0.8091485), array(0.70800695), array(0.73816036)]\n",
      "\n",
      "Sample 3:\n",
      "  Label    : cat\n",
      "  Encoding : [array(0.86190561), array(0.74723801), array(0.72188804), array(0.38755196), array(0.51138963)]\n",
      "\n",
      "Sample 4:\n",
      "  Label    : cat\n",
      "  Encoding : [array(0.82555715), array(0.71952171), array(0.78968455), array(0.70965053), array(0.72570918)]\n",
      "\n",
      "Sample 5:\n",
      "  Label    : cat\n",
      "  Encoding : [array(0.85667816), array(0.81378363), array(0.73935792), array(0.73883707), array(0.79031264)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the quantum encoded data\n",
    "with open(\"quantum_AFHQ_encoded.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# Print the first 5 quantum encoded vectors and their labels\n",
    "print(\"Quantum Encoded Outputs (First 5):\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"  Label    :\", data[\"labels\"][i])\n",
    "    print(\"  Encoding :\", data[\"quantum_encoded\"][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522def04-0487-4e59-830f-8a04ce5f4601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding cat images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:04<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding dog images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:57<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding wild images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:12<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# === Setup ===\n",
    "dataset_path = \"C:/Users/HP/encode/anantwave/Multi_class/train\"  # Update to AFHQ dataset path\n",
    "categories = [\"cat\", \"dog\", \"wild\"]  # Classes: Cat, Dog, Wildlife\n",
    "num_images_per_category = 1000\n",
    "all_features = []\n",
    "labels = []\n",
    "\n",
    "# === SIFT Feature Extraction ===\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros((128,))\n",
    "    return descriptors.mean(axis=0)\n",
    "\n",
    "# === Image Processing Loop ===\n",
    "for category in categories:\n",
    "    path = os.path.join(dataset_path, category)  # Paths for different categories\n",
    "    image_files = [f for f in os.listdir(path) if f.endswith(\".jpg\")][:num_images_per_category]\n",
    "    print(f\"Encoding {category} images...\")\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        try:\n",
    "            image_path = os.path.join(path, image_file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                continue\n",
    "            features = extract_features(image)\n",
    "            all_features.append(features)\n",
    "            labels.append(category)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff5ea7a-ebbf-4762-b02b-1c4bf5767fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete with adaptive qubit encoding and no resizing.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# === Standardization + PCA ===\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(all_features)\n",
    "\n",
    "# Dynamic number of PCA components (limit to 8)\n",
    "n_components = min(8, scaled_features.shape[1])\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_features = pca.fit_transform(scaled_features)\n",
    "\n",
    "# === Quantum Configuration ===\n",
    "n_qubits = n_components\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# QAOA Layer\n",
    "def qaoa_layer(gamma, beta, wires):\n",
    "    for i in range(len(wires)):\n",
    "        qml.CZ(wires=[wires[i], wires[(i + 1) % len(wires)]])\n",
    "    for i in range(len(wires)):\n",
    "        qml.RX(2 * gamma, wires=i)\n",
    "        qml.RZ(2 * beta, wires=i)\n",
    "\n",
    "# QNode\n",
    "@qml.qnode(dev)\n",
    "def quantum_model(x, gamma=0.5, beta=0.5):\n",
    "    qml.AmplitudeEmbedding(x / np.linalg.norm(x), wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qaoa_layer(gamma, beta, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# === Quantum Encoding ===\n",
    "quantum_outputs = []\n",
    "for vec in reduced_features:\n",
    "    vec_pnp = pnp.array(vec, requires_grad=False)\n",
    "    result = quantum_model(vec_pnp)\n",
    "    quantum_outputs.append(result)\n",
    "\n",
    "# === Save Output ===\n",
    "final_data = {\n",
    "    \"quantum_encoded\": quantum_outputs,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(\"quantum_real_time_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_data, f)\n",
    "\n",
    "print(\"Pipeline complete with adaptive qubit encoding and no resizing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb99f59e-8718-4def-9009-757e009a6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of Encoded Quantum Features:\n",
      "Label: cat, Quantum Output: [tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.51012803, requires_grad=True), tensor(0.41513213, requires_grad=True), tensor(-0.18260537, requires_grad=True)]\n",
      "Label: cat, Quantum Output: [tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.52362723, requires_grad=True), tensor(0.49620602, requires_grad=True), tensor(0.51134007, requires_grad=True)]\n",
      "Label: cat, Quantum Output: [tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.4839308, requires_grad=True), tensor(0.26844523, requires_grad=True), tensor(0.36065852, requires_grad=True)]\n",
      "Label: cat, Quantum Output: [tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.51233206, requires_grad=True), tensor(0.48817895, requires_grad=True), tensor(0.52181732, requires_grad=True)]\n",
      "Label: cat, Quantum Output: [tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.54030231, requires_grad=True), tensor(0.48536642, requires_grad=True), tensor(0.47165774, requires_grad=True), tensor(0.50666212, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Printing Head\n",
    "print(\"\\nPreview of Encoded Quantum Features:\")\n",
    "for i in range(min(5, len(quantum_outputs))):  # Ensure we don't exceed the length of the list\n",
    "    print(f\"Label: {labels[i]}, Quantum Output: {quantum_outputs[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1f6a0-d427-4568-a37c-3e80d791284d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anantwave)",
   "language": "python",
   "name": "anantwave"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
